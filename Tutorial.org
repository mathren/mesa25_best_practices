#+Title: Best practices - MESA Summer School 2025

* Late massive star evolution

Massive star models become numerically more challenging as they
evolve. Numerical issues manifest as plummeting timesteps. Broadly
speaking, these can be seeded in either "the core" (where nuclear
burning of heavy elements stiffens the equations) and/or "the
envelope" (where small timesteps result in waves and occasionally
spurious artificial accelerations). The two kind of issues can also
interact non-linearly, resulting in the majority of a grid crashing.

*N.B.:* this is not exclusively a "MESA" problem, but a result of the
physics being described by progressively stiffer equations that are
numerically more challenging to solve. This is why most (but notably
not all) stellar evolution codes stop at C core depletion at the
latest.

Here we will use a simple model of a 15M_{\odot} star (see
[[./15Msun_early_evol/][the work directory]]) to illustrate these
problems. In the interest of speed, we will use a 22-isotope network
and we have already evolved it beyond carbon core depletion (model
number =1261=).

:Hint:
You can inspect the [[./15Msun_early_evol/15M_early_evol.mod][model output]] and [[./15Msun_early_evol/15M_early_evol.data][profile]], or just look at the
[[./15Msun_early_evol/png/15Msun_early_evol.mp4][pgstar movie]] to see your initial conditions.
:end:

Ideally, we'd want to be able to run this to the onset of core
collapse, but again for summer school purposes, let's just try to get
to a central oxygen abundance of X_{O} \le 0.1 and call it a success.
However, to prevent a ZAMS model to terminate immediately, we set the
(for this particular model) equivalent upper-limit
$\log_{10}(T/[K])<9.35$ reached 3 timesteps earlier.

*N.B.:* =min_timestep_limit= is set to 0.1 seconds, too high for production
models past O core burning, but it's sufficiently low that one may
not want to continue the evolution in testing, and in this particular
case, we have tested that blindly lowering the =min_timestep_limit= will
only delay the issue, not fundamentally change it.

** Common situation: Running into a problem

Download the =15Msun_problem= folder. The main =inlist= points to
=inlist_problem= which is at this point is the same as =inlist_early_evol=
(use to create the pre-computed initial conditions) except for the
stopping criterion.

*N.B.:* It's not exactly a bare-bone model, but definitely not
science-ready!

After initializing MESA and running =./clean && ./mk= start from the
provided photo (=photos/x261=) with =./re x261= or even just =./re= (without
an argument =./re= will restart from the last photo saved on the disk,
which should still be =x261=, and you can use the command line =touch= to
update the time of last edit of a =photo= to trick MESA).

*N.B.:* We have modified the =./rn= bash script to add an extra check in
case you really want to start from the beginning. This is not
something you should do during this lab.

Watch your model evolve. The terminal output is often the quickest way
to get an idea of what's going on, but it may scroll too fast to look
at it. You can *pause (without killing) the run with =Ctrl-Z= and resume
it typing* =f g=.

At model =1266= you should hit the =hydro_failed= condition.

At this point, for an individual model I may fiddle a bit to find a
work-around (e.g., fiddling with increasing resolution, decreasing
=min_timestep_limit=), but that can often become a messy random walk in
the forest of MESA parameters. Sometimes, a problem cannot be worked
around and needs to be fixed.

** But what is the problem?

The terminal output indicates that MESA took a series of =retries=
before hitting =hydro_failed=.

#+DOWNLOADED: screenshot @ 2025-06-04 15:20:26
[[file:.org_notes_figures/Late_massive_star_evolution/2025-06-04_15-20-26_screenshot.png]]


The output also says that there has been 133 of these =retry=, (not all
at timestep). A =retry= means that the proposed solution of the ODEs you
are solving is not good enough (left and right hand-side still differ
too much, the difference is called *residual*), prompting MESA to =retry=
from the initial conditions of the previous timestep with a smaller
timestep size.

Another useful information is the value of =s% solver_call_number=, in
this case =1399=, which differs from the model number (here =1166=)
precisely because of the retries. This is the call to the solver that
resulted in the =hydro_failed=.

Let's collect more output about this.

*** MESA's debugging output
We will instruct MESA to provide debugging output we don't normally
want to see. To do this we will use a particular set of =controls= in
out inlist, which are described in the MESA documentation at
=$MESA_DIR/star/defaults/controls.defaults/= or [[https://docs.mesastar.org/en/latest/developing/debugging.html#step-1-activate-debugging-options][online]], and also
collected for convenience in
=$MESA_DIR/star/test_suite/debugging_stuff_for_inlists=. Don't worry, we
won't need to use /all/ of this!

Copy the content of this file in your =inlist_problem= in the =controls=
namelist (or "section"). Everything is commented (=!= in Fortran 90,
used also in the inlists which are not proper Fortran files).

Uncomment and set to =.true.= the =report_solver_progress= control:
#+begin_src fortran 90
  report_solver_progress = .true.
#+end_src

And then =./re= to restart. The run now produces more output per timestep,
and thus scrolls faster (but you can still pause it with =Ctrl-Z=), but
apart from that we haven't changed anything and it should crash in the
same way.

The solver call that crashes shows this:

#+DOWNLOADED: screenshot @ 2025-06-04 15:28:20
[[file:.org_notes_figures/Late_massive_star_evolution/2025-06-04_15-28-20_screenshot.png]]

Which is described in the MESA documentation [[https://docs.mesastar.org/en/latest/developing/debugging.html#step-2-run-the-model-and-find-the-bad-spot][here]]. After a line
declaring the current solver call number (=1399=), which "gold"
tolerance level we are applying, the reporting on each solver
iteration start. The line starting with =tol1= tells the level of
tolerances currently applied, if no solution can be found, this is
relaxed to =tol2= and later =tol3= after a set of user-specified number of
solver iterations.

For the lines produced at each iteration, the first column
says the current timestep (=1266=), the second shows the solver
iteration number for the current call (=1=, =2=, ...). The 10^{th} column
gives the name of the problematic equation (which can change from
iteration to iteration), and the 11^{th} gives the number of the
mesh point where the residual are maximum. The last-but-6^{th} column
also shows the variable likely to produce the largest residual.

This example shows that the problem is in cell =933= (so roughly in the
middle of the star, which has \sim1500+ cells) where the =equL= equation
(presumably the Luminosity equation) has a large residual. Moreover,
scrolling upward through the solver iterations we see that the
residual is jumping from negative to positive from iteration =20= to
iteration =21=. Finally, during these iterations, =lnd= (that is
physically, the density) is the problematic variable.

*** *Optional*: confirming this

Because MESA is searching for a solution with a Newton-Raphson solver,
the corrections applied at each iterations of the solver depend on the
derivatives of quantities (see excellent [[https://en.wikipedia.org/wiki/Newton%27s_method#/media/File:NewtonIteration_Ani.gif][wikipedia gif]] for intuition
on this): to find why this residual is bad, we need to check the
partial derivatives of the quantities entering the problematic
equation. Let's get some info about those by uncommenting and setting
in our inlist the following

#+begin_src fortran 90
solver_test_partials_call_number = 1399
solver_test_partials_iter_number = 21
solver_test_partials_k = 21
solver_test_partials_equ_name = 'equL'
solver_test_partials_var_name = 'lnd'
solver_test_partials_dx_0 = 1d-5
#+end_src

This tells MESA we want more output at solver call number =1399=, we
want to inspect the =21= iteration of the solver, and we want to see the
partial derivatives of the luminosity equation w.r.t. =lnd=. This will
also make MESA crash right after that iteration of the solver, scroll
up to see the output:




*N.B.:* At this stage you may also want to set
=solver_save_photo_call_number= equal to the solver call of the problem
(in our case =1399=) so MESA will save a =photo=
just before this solver call, saving you time to debug
** Finding a solution

There may be more than one! This is where computing stellar structure
and evolution models is a bit of an art, experience, trial and error,
and /many/ wasted CPUh.

** After you found the solution

If your solution implies changing at some point something in the setup
you should either:
1. re-run from the beginning (hoping that the introduced change does
   not make the model crash earlier or change any interpretation of the
   results)
2. if that is not possible and you're willing to change something
   "on-the-fly", try to implement this as a change from
   =run_star_extras.f90=.

While option 1. is desirable, it is not always possible, plus,
sometimes you may be willing to turn off some physics that acts on
timescales long compared to the remaining lifetime, or relax some
numerical criteria when things get too hard.

Option 2. can be done for example using the =extras_start_step= function
in =run_star_extras.f90=: add an if statement to catch "when" in the
evolution the change should happen (e.g., based on central abundances
or temperature) and change the values of entries in =controls= through
the =s%= pointer. For example, to change =max_model_number= (a =controls=
setting), you can overwrite your =inlist= with:
#+begin_src fortran 90
   s% max_model_number = 1000
#+end_src

*N.B.:* you can also use =b %= in the MESA =binary= module to change things
 of =binary_controls=.

Option 2. at least will minimize the amount of hand-holding required
for your models.

** Wrap up

Hopefully, what you have learned here can be helpful if further
problem arise, and more generally. As you've seen, this is a significant
amount of work, and often you can use intuition to take short cuts.

To identify the problem, the first thing is to make plots. It is quick
and often useful to look at =pgplots=. Very often, with a bit of physical
intuition and experience one can identify the problem just looking at
the model.

*N.B.:* At this stage, you may want to look at variables you don't
necessarily focus on for your science: sometimes it's things you don't
care about that grind your model(s) to a halt! Stellar evolution is a
highly non-linear problem. Sometimes changing axes (quantities and
scale) to change perspective also helps.


=pgplots= may not be that pretty to look at, but they can be very
helpful to spot problems and depending on your science case you may be
able to afford a band-aid solution. But sometimes you need to know
what is the root cause, which equation is yielding the largest
residual and driving the decrease in timesteps.

For the problem of velocities we worked on, typical approaches are to
"put a lid" on the star, increasing the surface pressure (e.g. with
=P_extra_factor=), increasing wind mass-loss rates to "get rid" of the
envelope, etc. It's up to you to experiment!

*** Full solution

An inlist with the full solution is provided as a hidden file
=.inlist_solution=. You can rename it and/or point your main =inlist= to
it (MESA will read a hidden file!)

** TODO

- [ ] more onpgplots?
- [ ] describe =report_solver_progress= output (see )
